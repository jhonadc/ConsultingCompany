import logo from '@/images/clients/aiact/logomark-dark.svg'
import imageHero from './hero.jpg'
import imageJennyWilson from './emily-selman.jpg'

export const caseStudy = {
  client: 'Artificial Intelligence Act (AI Act)',
  title: 'Classify risk and build AI-literate teams',
  description:
    'The EU AI Act introduces tiered obligations for AI systems. We determine whether yours is high-risk and deliver engaging AI-literacy training that makes every team member care—and comply.',
  summary: [
    // WHY IT MATTERS
    'The AI Act’s risk-based framework bans certain uses outright and puts rigorous controls on “high-risk” systems. Misclassification means product delays, penalties and reputational damage.',
    // HOW WE HELP  (incl. your background)
    'Drawing on 12 years as a machine-learning engineer and EU policy adviser, I translate the 170-page Act into plain-language playbooks, run hands-on risk-classification workshops and deliver interactive training that sticks.',
  ],
  logo,
  image: { src: imageHero },
  date: '2024-06',
  service: 'Risk classification, AI-literacy training',
  testimonial: {
    author: { name: 'Confidential CTO', role: 'European SaaS scale-up' },
    content:
      'Their plain-spoken workshops turned a daunting regulation into actionable next steps. Our engineers now flag AI-Act issues before legal even asks.',
  },
}

export const metadata = {
  title: `${caseStudy.client} Case Study`,
  description: caseStudy.description,
}

## Overview

The **EU Artificial Intelligence Act** (expected in the _Official Journal 2024_) is the world’s first horizontal AI law.  
It:

- Categorises AI systems as **_unacceptable-, high-, limited-_ or _minimal-risk_**.
- Imposes **conformity assessments, technical documentation, human oversight and robustness tests** on high-risk systems.
- Requires **AI-literacy** so that staff designing or deploying AI understand its limits, risks and legal duties.
- Introduces heavy fines (up to **€35 million or 7 %** of global turnover) for non-compliance.

### How we make it painless

1. **Rapid risk triage** – a one-day workshop and checklist to decide if your product is banned, high-, or lower-risk.
2. **Clear, visual reports** – a two-page decision log you can hand to regulators or execs.
3. **AI-literacy bootcamps** – bite-sized sessions, demos and quizzes that bring the Act to life for engineers, UX and product owners.
4. **Change-champion toolkit** – slide decks, cheat-sheets and Slack snippets so internal leads can keep momentum after we leave.

All sessions are led by me—**former ML engineer, certified data-protection pro and ex-policy adviser to the European Commission—**so you get both technical depth and regulatory nuance in plain English (and German).

## What we did

<TagList>
  <TagListItem>Risk classification</TagListItem>
  <TagListItem>AI-literacy workshops</TagListItem>
  <TagListItem>Policy briefing decks</TagListItem>
  <TagListItem>Documentation templates</TagListItem>
</TagList>

<Blockquote
  author={{ name: 'Confidential CTO', role: 'European SaaS scale-up' }}
  image={{ src: imageJennyWilson }}
>
  Their plain-spoken workshops turned a daunting regulation into actionable next
  steps. Our engineers now flag AI-Act issues before legal even asks.
</Blockquote>

<StatList>
  <StatListItem value="25" label="Systems classified" />
  <StatListItem value="500 +" label="People trained" />
  <StatListItem value="95 %" label="Training completion" />
  <StatListItem value="4 wks" label="Average turnaround" />
</StatList>
